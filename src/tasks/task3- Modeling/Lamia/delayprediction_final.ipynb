{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cb3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50998df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df_ohe = pd.read_parquet('d:/OMDENA/BERLIN/Parquet/new_df_ohe.parquet')\n",
    "X = new_df_ohe.drop('DELAY_ARR', axis=1)\n",
    "y = new_df_ohe[['DELAY_ARR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d158c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3298304, 172)\n",
      "(3298304, 1)\n",
      "(1413560, 172)\n",
      "(1413560, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Sandardization of data ###\n",
    "X0 = X.values\n",
    "y0 = y.values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    " \n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X0)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y0)\n",
    " \n",
    "# Generating the standardized values of X and y\n",
    "X0=PredictorScalerFit.transform(X0)\n",
    "y0=TargetVarScalerFit.transform(y0)\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size=0.3, random_state=42)\n",
    " \n",
    "# check with the shapes of Training and testing datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e478eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_ohe=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d597a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constract the basemodel\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, input_shape=(172,), kernel_initializer='normal', activation='relu',trainable=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=50, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d7897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model over different kfolds\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71effa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20615/20615 [==============================] - 44s 2ms/step - loss: 0.9407\n",
      "Epoch 2/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.9311\n",
      "Epoch 3/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9276\n",
      "Epoch 4/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.9255\n",
      "Epoch 5/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9236\n",
      "Epoch 6/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.9215\n",
      "Epoch 7/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9201\n",
      "Epoch 8/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9187\n",
      "Epoch 9/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9175\n",
      "Epoch 10/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9159\n",
      "Epoch 11/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9140\n",
      "Epoch 12/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9141\n",
      "Epoch 13/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9133\n",
      "Epoch 14/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9120\n",
      "Epoch 15/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9119\n",
      "Epoch 16/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9108\n",
      "Epoch 17/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9096\n",
      "Epoch 18/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9088\n",
      "Epoch 19/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9084\n",
      "Epoch 20/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9080\n",
      "Epoch 21/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9077\n",
      "Epoch 22/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9070\n",
      "Epoch 23/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9064\n",
      "Epoch 24/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9066\n",
      "Epoch 25/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9052\n",
      "Epoch 26/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9040\n",
      "Epoch 27/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9036\n",
      "Epoch 28/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9033\n",
      "Epoch 29/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9015\n",
      "Epoch 30/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9018\n",
      "Epoch 31/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9008\n",
      "Epoch 32/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8991\n",
      "Epoch 33/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8993\n",
      "Epoch 34/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8989\n",
      "Epoch 35/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8970\n",
      "Epoch 36/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8969\n",
      "Epoch 37/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8968\n",
      "Epoch 38/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8960\n",
      "Epoch 39/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8968\n",
      "Epoch 40/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8953\n",
      "Epoch 41/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8935\n",
      "Epoch 42/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8944\n",
      "Epoch 43/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8931\n",
      "Epoch 44/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8918\n",
      "Epoch 45/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8912\n",
      "Epoch 46/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.8907\n",
      "Epoch 47/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.8904\n",
      "Epoch 48/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.8898\n",
      "Epoch 49/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.8905\n",
      "Epoch 50/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8892\n",
      "5154/5154 [==============================] - 5s 908us/step\n",
      "Epoch 1/50\n",
      "20615/20615 [==============================] - 40s 2ms/step - loss: 0.9409\n",
      "Epoch 2/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9319\n",
      "Epoch 3/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9277\n",
      "Epoch 4/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9247\n",
      "Epoch 5/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9230\n",
      "Epoch 6/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9213\n",
      "Epoch 7/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9187\n",
      "Epoch 8/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9173\n",
      "Epoch 9/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9160\n",
      "Epoch 10/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9143\n",
      "Epoch 11/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9126\n",
      "Epoch 12/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9126\n",
      "Epoch 13/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9112\n",
      "Epoch 14/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9096\n",
      "Epoch 15/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9089\n",
      "Epoch 16/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9082\n",
      "Epoch 17/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9068\n",
      "Epoch 18/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9063\n",
      "Epoch 19/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9060\n",
      "Epoch 20/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9048\n",
      "Epoch 21/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9054\n",
      "Epoch 22/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9039\n",
      "Epoch 23/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9031\n",
      "Epoch 24/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9033\n",
      "Epoch 25/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9038\n",
      "Epoch 26/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9021\n",
      "Epoch 27/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9013\n",
      "Epoch 28/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9008\n",
      "Epoch 29/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9008\n",
      "Epoch 30/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8993\n",
      "Epoch 31/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8994\n",
      "Epoch 32/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9005\n",
      "Epoch 33/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8983\n",
      "Epoch 34/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8984\n",
      "Epoch 35/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8994\n",
      "Epoch 36/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8984\n",
      "Epoch 37/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8972\n",
      "Epoch 38/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8983\n",
      "Epoch 39/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8963\n",
      "Epoch 40/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8968\n",
      "Epoch 41/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8969\n",
      "Epoch 42/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8961\n",
      "Epoch 43/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8950\n",
      "Epoch 44/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8949\n",
      "Epoch 45/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8953\n",
      "Epoch 46/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8947\n",
      "Epoch 47/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8947\n",
      "Epoch 48/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8949\n",
      "Epoch 49/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8949\n",
      "Epoch 50/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8944\n",
      "5154/5154 [==============================] - 17s 3ms/step\n",
      "Epoch 1/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9448\n",
      "Epoch 2/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.9347\n",
      "Epoch 3/50\n",
      "20615/20615 [==============================] - 36s 2ms/step - loss: 0.9318\n",
      "Epoch 4/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9285\n",
      "Epoch 5/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9263\n",
      "Epoch 6/50\n",
      "20615/20615 [==============================] - 40s 2ms/step - loss: 0.9237\n",
      "Epoch 7/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9209\n",
      "Epoch 8/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9196\n",
      "Epoch 9/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9179\n",
      "Epoch 10/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9163\n",
      "Epoch 11/50\n",
      "20615/20615 [==============================] - 40s 2ms/step - loss: 0.9146\n",
      "Epoch 12/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9139\n",
      "Epoch 13/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9127\n",
      "Epoch 14/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9121\n",
      "Epoch 15/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9108\n",
      "Epoch 16/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9096\n",
      "Epoch 17/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9084\n",
      "Epoch 18/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9098\n",
      "Epoch 19/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9091\n",
      "Epoch 20/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9084\n",
      "Epoch 21/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9071\n",
      "Epoch 22/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9052\n",
      "Epoch 23/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9042\n",
      "Epoch 24/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9050\n",
      "Epoch 25/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9048\n",
      "Epoch 26/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9033\n",
      "Epoch 27/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9040\n",
      "Epoch 28/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9038\n",
      "Epoch 29/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9030\n",
      "Epoch 30/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9041\n",
      "Epoch 31/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9021\n",
      "Epoch 32/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9021\n",
      "Epoch 33/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9021\n",
      "Epoch 34/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9019\n",
      "Epoch 35/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8994\n",
      "Epoch 36/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8996\n",
      "Epoch 37/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8991\n",
      "Epoch 38/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8985\n",
      "Epoch 39/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8986\n",
      "Epoch 40/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8966\n",
      "Epoch 41/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8974\n",
      "Epoch 42/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8984\n",
      "Epoch 43/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8969\n",
      "Epoch 44/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8967\n",
      "Epoch 45/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8965\n",
      "Epoch 46/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8956\n",
      "Epoch 47/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8939\n",
      "Epoch 48/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8946\n",
      "Epoch 49/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8922\n",
      "Epoch 50/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8938\n",
      "5154/5154 [==============================] - 5s 1ms/step\n",
      "Epoch 1/50\n",
      "20615/20615 [==============================] - 41s 2ms/step - loss: 0.9452\n",
      "Epoch 2/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9360\n",
      "Epoch 3/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9320\n",
      "Epoch 4/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9296\n",
      "Epoch 5/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9274\n",
      "Epoch 6/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9251\n",
      "Epoch 7/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9241\n",
      "Epoch 8/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9226\n",
      "Epoch 9/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9212\n",
      "Epoch 10/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9197\n",
      "Epoch 11/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9176\n",
      "Epoch 12/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9179\n",
      "Epoch 13/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9163\n",
      "Epoch 14/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9153\n",
      "Epoch 15/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9139\n",
      "Epoch 16/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9133\n",
      "Epoch 17/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9135\n",
      "Epoch 18/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9125\n",
      "Epoch 19/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9115\n",
      "Epoch 20/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9111\n",
      "Epoch 21/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9104\n",
      "Epoch 22/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9107\n",
      "Epoch 23/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9109\n",
      "Epoch 24/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9091\n",
      "Epoch 25/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9084\n",
      "Epoch 26/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9065\n",
      "Epoch 27/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9063\n",
      "Epoch 28/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9049\n",
      "Epoch 29/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9030\n",
      "Epoch 30/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9046\n",
      "Epoch 31/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9028\n",
      "Epoch 32/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9032\n",
      "Epoch 33/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9017\n",
      "Epoch 34/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9013\n",
      "Epoch 35/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8997\n",
      "Epoch 36/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8998\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8978\n",
      "Epoch 38/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8988\n",
      "Epoch 39/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8986\n",
      "Epoch 40/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8973\n",
      "Epoch 41/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8980\n",
      "Epoch 42/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8966\n",
      "Epoch 43/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8969\n",
      "Epoch 44/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8956\n",
      "Epoch 45/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8954\n",
      "Epoch 46/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8947\n",
      "Epoch 47/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8929\n",
      "Epoch 48/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8931\n",
      "Epoch 49/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8922\n",
      "Epoch 50/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8921\n",
      "5154/5154 [==============================] - 8s 1ms/step\n",
      "Epoch 1/50\n",
      "20615/20615 [==============================] - 40s 2ms/step - loss: 0.9414\n",
      "Epoch 2/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9311\n",
      "Epoch 3/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9275\n",
      "Epoch 4/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9247\n",
      "Epoch 5/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.9218\n",
      "Epoch 6/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9195\n",
      "Epoch 7/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9189\n",
      "Epoch 8/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9170\n",
      "Epoch 9/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9156\n",
      "Epoch 10/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9139\n",
      "Epoch 11/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9123\n",
      "Epoch 12/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9121\n",
      "Epoch 13/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9102\n",
      "Epoch 14/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9096\n",
      "Epoch 15/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9088\n",
      "Epoch 16/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9079\n",
      "Epoch 17/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9069\n",
      "Epoch 18/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9068\n",
      "Epoch 19/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9051\n",
      "Epoch 20/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9049\n",
      "Epoch 21/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9040\n",
      "Epoch 22/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.9037\n",
      "Epoch 23/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9035\n",
      "Epoch 24/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9028\n",
      "Epoch 25/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9019\n",
      "Epoch 26/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9018\n",
      "Epoch 27/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9023\n",
      "Epoch 28/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9011\n",
      "Epoch 29/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9006\n",
      "Epoch 30/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8997\n",
      "Epoch 31/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8994\n",
      "Epoch 32/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.9000\n",
      "Epoch 33/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8991\n",
      "Epoch 34/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8978\n",
      "Epoch 35/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8985\n",
      "Epoch 36/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8976\n",
      "Epoch 37/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8971\n",
      "Epoch 38/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8968\n",
      "Epoch 39/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8969\n",
      "Epoch 40/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8947\n",
      "Epoch 41/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8952\n",
      "Epoch 42/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8947\n",
      "Epoch 43/50\n",
      "20615/20615 [==============================] - 39s 2ms/step - loss: 0.8936\n",
      "Epoch 44/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8938\n",
      "Epoch 45/50\n",
      "20615/20615 [==============================] - 37s 2ms/step - loss: 0.8932\n",
      "Epoch 46/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8915\n",
      "Epoch 47/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8906\n",
      "Epoch 48/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8905\n",
      "Epoch 49/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8902\n",
      "Epoch 50/50\n",
      "20615/20615 [==============================] - 38s 2ms/step - loss: 0.8898\n",
      "5154/5154 [==============================] - 5s 916us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "290924e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -0.88 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88a39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25768/25768 [==============================] - 42s 2ms/step - loss: 0.9412\n",
      "Epoch 2/50\n",
      "25768/25768 [==============================] - 41s 2ms/step - loss: 0.9312\n",
      "Epoch 3/50\n",
      "25768/25768 [==============================] - 41s 2ms/step - loss: 0.9276\n",
      "Epoch 4/50\n",
      "25768/25768 [==============================] - 41s 2ms/step - loss: 0.9240\n",
      "Epoch 5/50\n",
      "25768/25768 [==============================] - 41s 2ms/step - loss: 0.9218\n",
      "Epoch 6/50\n",
      "25768/25768 [==============================] - 42s 2ms/step - loss: 0.9193\n",
      "Epoch 7/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9185\n",
      "Epoch 8/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9159\n",
      "Epoch 9/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9160\n",
      "Epoch 10/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9149\n",
      "Epoch 11/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9139\n",
      "Epoch 12/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9132\n",
      "Epoch 13/50\n",
      "25768/25768 [==============================] - 44s 2ms/step - loss: 0.9132\n",
      "Epoch 14/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9133\n",
      "Epoch 15/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9117\n",
      "Epoch 16/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9117\n",
      "Epoch 17/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9107\n",
      "Epoch 18/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9099\n",
      "Epoch 19/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9096\n",
      "Epoch 20/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9077\n",
      "Epoch 21/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9073\n",
      "Epoch 22/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9073\n",
      "Epoch 23/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9065\n",
      "Epoch 24/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9070\n",
      "Epoch 25/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9059\n",
      "Epoch 26/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9037\n",
      "Epoch 27/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9036\n",
      "Epoch 28/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9029\n",
      "Epoch 29/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9020\n",
      "Epoch 30/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9016\n",
      "Epoch 31/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.9008\n",
      "Epoch 32/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8992\n",
      "Epoch 33/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8980\n",
      "Epoch 34/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8974\n",
      "Epoch 35/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8961\n",
      "Epoch 36/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8960\n",
      "Epoch 37/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8935\n",
      "Epoch 38/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8938\n",
      "Epoch 39/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8945\n",
      "Epoch 40/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8935\n",
      "Epoch 41/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8938\n",
      "Epoch 42/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8933\n",
      "Epoch 43/50\n",
      "25768/25768 [==============================] - 44s 2ms/step - loss: 0.8935\n",
      "Epoch 44/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8924\n",
      "Epoch 45/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8915\n",
      "Epoch 46/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8918\n",
      "Epoch 47/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8905\n",
      "Epoch 48/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8908\n",
      "Epoch 49/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8912\n",
      "Epoch 50/50\n",
      "25768/25768 [==============================] - 43s 2ms/step - loss: 0.8891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function baseline_model at 0x000001825C6928B0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=128\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function baseline_model at 0x000001825C6928B0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=128\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasRegressor(\n",
       "\tmodel=<function baseline_model at 0x000001825C6928B0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=128\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=50\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the estimator on the training data\n",
    "estimator.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3601bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11044/11044 [==============================] - 10s 929us/step\n"
     ]
    }
   ],
   "source": [
    "#predict on test data\n",
    "prediction = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a77fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "estimator.model_.save(\"model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c9bf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07bb8240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44174/44174 [==============================] - 42s 949us/step\n"
     ]
    }
   ],
   "source": [
    "#evaluate on test data\n",
    "prediction1=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a189f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To interpret the prediction we have to inverse the scaling of predictions \n",
    "\n",
    "# Scaling the predicted delay data back to original delay scale\n",
    "Predictions1=TargetVarScalerFit.inverse_transform(prediction1)\n",
    " \n",
    "# Scaling the y_test delay data back to original delay scale\n",
    "y_test_orig1=TargetVarScalerFit.inverse_transform(y_test)\n",
    " \n",
    "# Scaling the test data back to original scale\n",
    "Test_Data1=PredictorScalerFit.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96bfccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error =  np.abs(y_test_orig - Predictions)\n",
    "mean_error = np.mean(train_error)\n",
    "min_error = np.min(train_error)\n",
    "max_error = np.max(train_error)\n",
    "std_error = np.std(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d11dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.06697496851646 0.00028991699220171085 15826.619812011722 299.23073669229143\n"
     ]
    }
   ],
   "source": [
    "print(mean_error, min_error, max_error, std_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ac904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the model to predict a single value using a single data line, in our case , X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bad867d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the raw to list \n",
    "datalist=X_test[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "319dd440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 529ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02165222]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the predictor needs as input an array of matrix like input, that's why i use list of datalist\n",
    "model.predict(np.array([datalist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13b4eaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02165222], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the prediction obtained are scaled\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f781a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "#getting the real value of prediction\n",
    "reverse=TargetVarScalerFit.inverse_transform(model.predict(np.array([ss])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee705597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.55426"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final Prediction:\n",
    "reverse[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
